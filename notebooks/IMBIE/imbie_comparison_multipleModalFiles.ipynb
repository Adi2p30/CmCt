{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input ice sheet model should be a netCDF file. \n",
    "\n",
    "\n",
    "### `Lithk` variable\n",
    "The uploaded model to contain thickness data (the `lithk` variable) for the comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from datetime import timedelta \n",
    "import cftime \n",
    "from datetime import datetime\n",
    "\n",
    "# note: suppress numpy.dtype size changed warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure IMBIE comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the flag for the ice sheet region Greenland or Antarctica\n",
    "icesheet = \"Antarctica\"# Change to \"Antarctica\" or \"Greenland\"\n",
    "\n",
    "# Set start and end dates\n",
    "start_date = '2006-01-01'\n",
    "end_date ='2014-01-01'\n",
    "\n",
    "#Set density of ice\n",
    "rho_ice = 918 # (kg/m^3)\n",
    "\n",
    "\n",
    "#output file dirctory\n",
    "output_path='/home/jovyan/CmCt/notebooks/IMBIE/'\n",
    "\n",
    "# Select  variable for mass balance comparision\n",
    "mass_balance_column=\"Cumulative mass balance (Gt)\"# \"Cumulative dynamics mass balance anomaly (Gt)\"\n",
    "if mass_balance_column == \"Cumulative mass balance (Gt)\":\n",
    "    mass_balance_type = \"total\"\n",
    "elif mass_balance_column == \"Cumulative dynamics mass balance anomaly (Gt)\":\n",
    "    mass_balance_type = \"dynamic\"\n",
    "\n",
    "\n",
    "\n",
    "# Set shapefile path and projection and IMBIE csv_file\n",
    "if icesheet == \"Greenland\":\n",
    "    projection = \"EPSG:3413\"  # Greenland\n",
    "\n",
    "    #Set the shape data dir path\n",
    "    shape_filename = \"/home/jovyan/CmCt/data/IMBIE/Greenland_Basins_PS_v1.4.2/Greenland_Basins_PS_v1.4.2.shp\"\n",
    "    #Set the observation data dir path\n",
    "    obs_filename = '/home/jovyan/CmCt/data/IMBIE/imbie_greenland_2022_Gt_partitioned_v0.csv'\n",
    "    # obs_filename = '/home/jovyan/CmCt/data/IMBIE/imbie_greenland_2021_Gt.csv'\n",
    "\n",
    "    ##Set the Region observation data dir path\n",
    "    obs_east_filename = None\n",
    "    obs_west_filename = None\n",
    "    obs_peninsula_filename = None\n",
    "    \n",
    "elif icesheet== \"Antarctica\":\n",
    "    projection = \"EPSG:3031\"  # Antarctica  \n",
    "    \n",
    "    #Set the shape data dir path\n",
    "    shape_filename = \"/home/jovyan/CmCt/data/IMBIE/ANT_Basins_IMBIE2_v1.6/ANT_Basins_IMBIE2_v1.6.shp\"\n",
    "    #Set the observation data dir path\n",
    "    obs_filename = '/home/jovyan/CmCt/data/IMBIE/imbie_antarctica_2022_Gt_partitioned_v0.csv'\n",
    "    # obs_filename = '/home/jovyan/CmCt/notebooks/IMBIE/imbie_antarctica_2021_Gt.csv'\n",
    "    \n",
    "    ##Set the Region observation data dir path\n",
    "    obs_east_filename = '/home/jovyan/CmCt/data/IMBIE/imbie_east_antarctica_2022_Gt_partitioned_v0.csv'\n",
    "    obs_west_filename = '/home/jovyan/CmCt/data/IMBIE/imbie_west_antarctica_2022_Gt_partitioned_v0.csv'\n",
    "    obs_peninsula_filename= '/home/jovyan/CmCt/data/IMBIE/imbie_antarctic_peninsula_2022_Gt_partitioned_v0.csv'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid iceshee value. Must be 'Greenland' or 'Antarctica'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if  observation file exists\n",
    "if not os.path.exists(obs_filename):\n",
    "    raise FileNotFoundError(f\"Observation file not found: {obs_filename}\")\n",
    "\n",
    "if icesheet== \"Antarctica\":   \n",
    "    # Check if regional observation files exist \n",
    "    if not os.path.exists(obs_east_filename):\n",
    "        raise FileNotFoundError(f\"Observation file not found: {obs_east_filename}\")\n",
    "    if not os.path.exists(obs_west_filename):\n",
    "        raise FileNotFoundError(f\"Observation file not found: {obs_west_filename}\")\n",
    "    if not os.path.exists(obs_peninsula_filename):\n",
    "        raise FileNotFoundError(f\"Observation file not found: {obs_peninsula_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the selcted dates are within the range of model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_datarange(time_var):\n",
    "\n",
    "    # Get the minimum and maximum values directly from the time variable\n",
    "    min_time = time_var.values.min()\n",
    "    max_time = time_var.values.max()\n",
    "    \n",
    "    print(f\"Time range: {min_time} to {max_time}\")\n",
    "    # Check if the time is in numpy.datetime64 or cftime format\n",
    "    if isinstance(min_time, np.datetime64) and isinstance(max_time, np.datetime64):\n",
    "        # Convert start_date and end_date to numpy.datetime64 for comparison\n",
    "        fomatted_start_date = np.datetime64(start_date)\n",
    "        fomatted_end_date = np.datetime64(end_date)\n",
    "    \n",
    "    elif isinstance(min_time, cftime.DatetimeNoLeap) and isinstance(max_time, cftime.DatetimeNoLeap):\n",
    "        # Convert start and end dates to cftime.DatetimeNoLeap for comparison\n",
    "        start_date_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end_date_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        fomatted_start_date = cftime.DatetimeNoLeap(start_date_dt.year, start_date_dt.month, start_date_dt.day)\n",
    "        fomatted_end_date = cftime.DatetimeNoLeap(end_date_dt.year, end_date_dt.month, end_date_dt.day)\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported time format in the dataset.\")\n",
    "    \n",
    "    \n",
    "    # Check if the selected start and end dates are within the range\n",
    "    if min_time <= fomatted_start_date <= max_time and min_time <= fomatted_end_date <= max_time:\n",
    "        print(f\"The selected dates {start_date} and {end_date} are within the range of the model data.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Error: The selected dates {start_date} or {end_date} are out of range. Model data time range is from {min_time} to {max_time}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model data and calculate  model mass balance for each basin and total mass balance for whole region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_data(nc_filename):\n",
    "    #Model data\n",
    "    gis_ds = xr.open_dataset(nc_filename)\n",
    "    lithk = gis_ds['lithk']\n",
    "    time_var = gis_ds['time']\n",
    "    \n",
    "    # Check the selcted dates are within the range of model data\n",
    "    check_datarange(time_var)\n",
    "        \n",
    "    # Interpolate lithk values at the start and end dates\n",
    "    lithk_start = lithk.interp(time=start_date).data.transpose().flatten()\n",
    "    lithk_end = lithk.interp(time=end_date).data.transpose().flatten()\n",
    "    \n",
    "    # Calculate the difference\n",
    "    lithk_delta = lithk_end - lithk_start\n",
    "    \n",
    "    # Replace NaN values with 0\n",
    "    lithk_delta[np.isnan(lithk_delta)] = 0\n",
    "    \n",
    "    \n",
    "    # Change Ice thickness unit from (m) to mass (kg) to gigatonnes(Gt)\n",
    "    # ice thickness*area* density of ice* 1e-12\n",
    "    #calculate area = x_resolution*y_resolution\n",
    "    x_coords = gis_ds['x'].values\n",
    "    y_coords = gis_ds['y'].values\n",
    "    x_resolution = abs(x_coords[1] - x_coords[0])\n",
    "    y_resolution = abs(y_coords[1] - y_coords[0])\n",
    "    \n",
    "    lithk_delta = (lithk_delta * x_resolution*y_resolution)*rho_ice * 1e-12\n",
    "    \n",
    "    \n",
    "    # Create a list of Point geometries from coordinate grids\n",
    "    points = [Point(x, y) for x in x_coords for y in y_coords]\n",
    "    \n",
    "    # Flatten lithk_delta to match the points list \n",
    "    lithk_delta_flat = lithk_delta.flatten()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    lithk_df = pd.DataFrame({\n",
    "        'geometry': points,\n",
    "        'lithk_delta': lithk_delta_flat\n",
    "    })\n",
    "    \n",
    "    # Convert DataFrame to GeoDataFrame\n",
    "    lithk_gdf = gpd.GeoDataFrame(lithk_df, geometry='geometry', crs=projection)\n",
    "    \n",
    "    # Load basin shapefile \n",
    "    basins_gdf = gpd.read_file(shape_filename)\n",
    "    \n",
    "    # Perform spatial join\n",
    "    joined_gdf = gpd.sjoin(lithk_gdf, basins_gdf, how=\"inner\", predicate='intersects')\n",
    "    \n",
    "    # Sum lithk_delta values by basin\n",
    "    if icesheet == \"Greenland\":\n",
    "         # Sum lithk_delta values by subregion column\n",
    "        basin_mass_change_sums = joined_gdf.groupby('SUBREGION1')['lithk_delta'].sum()\n",
    "        # Sum lithk_delta values by the 'Regions' column\n",
    "        region_mass_change_sums = None  # No regions for Greenland\n",
    "    elif icesheet == \"Antarctica\":\n",
    "        # Sum lithk_delta values by subregion column\n",
    "        basin_mass_change_sums = joined_gdf.groupby('Subregion')['lithk_delta'].sum()\n",
    "        # Sum lithk_delta values by the 'Regions' column\n",
    "        region_mass_change_sums = joined_gdf.groupby('Regions')['lithk_delta'].sum()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid iceshee value. Must be 'Greenland' or 'Antarctica'.\")\n",
    "    \n",
    "    # Sum all of the basin mass change\n",
    "    model_total_mass_balance= basin_mass_change_sums.sum()\n",
    "    \n",
    "    # Return all results as a dictionary\n",
    "    return {\n",
    "        'model_total_mass_balance': model_total_mass_balance,\n",
    "        'basin_mass_change_sums': basin_mass_change_sums,\n",
    "        'region_mass_change_sums': region_mass_change_sums\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMBIE data date format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert fractional years to a precise datetime format\n",
    "def fractional_year_to_date(year):\n",
    "    year_int = int(year)  # Extract the integer part (the full year)\n",
    "    fraction = year - year_int  # Extract the fractional part\n",
    "    \n",
    "    # Start at the beginning of the year\n",
    "    start_of_year = pd.Timestamp(f'{year_int}-01-01')\n",
    "    \n",
    "    # Determine if it's a leap year\n",
    "    if pd.Timestamp(f'{year_int}-12-31').is_leap_year:\n",
    "        total_days_in_year = 366\n",
    "    else:\n",
    "        total_days_in_year = 365\n",
    "    \n",
    "    # Convert the fractional part into the corresponding number of days\n",
    "    fractional_days = fraction * total_days_in_year\n",
    "    \n",
    "    # Add the fractional days to the start of the year to get the correct date\n",
    "    return start_of_year + timedelta(days=fractional_days)\n",
    "\n",
    "\n",
    "# Group the data by year\n",
    "def assign_month_order(group):\n",
    "    # Get the month of the first entry for the year\n",
    "    first_month = group['Date'].dt.month.iloc[0]\n",
    "    \n",
    "    # Create a month order starting from the first month and increasing by 1 for each subsequent entry\n",
    "    group['Month_Order'] = range(first_month, first_month + len(group))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract IMBIE mass balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_MassBalance(obs_filename,start_date,end_date):\n",
    "    \n",
    "    # Load the CSV file\n",
    "    mass_balance_data = pd.read_csv(obs_filename)\n",
    "    \n",
    "    # Column names\n",
    "    date_column = 'Year'\n",
    "    \n",
    "    # Ensure the 'Year' column is treated as float to capture the fractional year part\n",
    "    mass_balance_data['Year'] = mass_balance_data['Year'].astype(float)\n",
    "    \n",
    "    # Apply the conversion function to the 'Year' column\n",
    "    mass_balance_data['Date'] = mass_balance_data['Year'].apply(fractional_year_to_date)\n",
    "  \n",
    "    # Sort the data by 'Date' column to ensure it’s in increasing order of both year and fraction\n",
    "    mass_balance_data = mass_balance_data.sort_values(by='Date')\n",
    "      \n",
    "    # Apply the function to each group of data (grouped by the year)\n",
    "    mass_balance_data = mass_balance_data.groupby(mass_balance_data['Date'].dt.year).apply(assign_month_order)\n",
    "    \n",
    "    # Convert 'Year' column to year-month-01 format where month is 'Month_Order'\n",
    "    mass_balance_data['Year'] = mass_balance_data.apply(lambda row: f\"{row['Date'].year}-{str(row['Month_Order']).zfill(2)}-01\", axis=1)\n",
    "    \n",
    "    # Reset the index to flatten the multi-index structure\n",
    "    mass_balance_data = mass_balance_data.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    # Check if the column exists in the DataFrame\n",
    "    if mass_balance_column not in mass_balance_data.columns:\n",
    "        raise ValueError(f\"Error: The column '{mass_balance_column}' does not exist in the CSV file.\")\n",
    "\n",
    "    \n",
    "    # Filter the data for the end date\n",
    "    end_data = mass_balance_data[mass_balance_data['Year'] == end_date]    \n",
    "    if end_data.empty:\n",
    "        raise ValueError(f\"Error: No data available for the end date {end_date}.\")\n",
    "    mass_balance_end_value = end_data[mass_balance_column].iloc[-1]  # Last value before or at the end date\n",
    "\n",
    "    \n",
    "    # Filter the data for one date before the start date\n",
    "    data_before_start_date = mass_balance_data[mass_balance_data[date_column] < start_date]\n",
    "    if data_before_start_date.empty:\n",
    "        raise ValueError(f\"Error: No data available before the start date {start_date}.\")\n",
    "    mass_balance_start_value = data_before_start_date[mass_balance_column].iloc[-1]  # Last value before start date\n",
    "    \n",
    "    # Subtract the two values to get the total mass balance change\n",
    "    IMBIE_total_mass_change_sum = mass_balance_end_value - mass_balance_start_value\n",
    "    \n",
    "    return IMBIE_total_mass_change_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mass balance difference of IMBIE and model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_IMBIE(obs_filename, start_date, end_date, icesheet, basin_result,obs_east_filename=None, obs_west_filename=None, obs_peninsula_filename=None):\n",
    "    results = {}\n",
    "\n",
    "    # model mass balance\n",
    "    model_total_mass_balance = basin_result['model_total_mass_balance']\n",
    "    \n",
    "    # IMBIE total mass balance\n",
    "    IMBIE_total_mass_change_sum = sum_MassBalance(obs_filename, start_date, end_date)\n",
    "    \n",
    "    # Calculate difference of IMBIE-model mass change\n",
    "    delta_masschange = IMBIE_total_mass_change_sum - model_total_mass_balance\n",
    "    \n",
    "    # Store total mass balance results in the dictionary\n",
    "    results['IMBIE_total_mass_change_sum'] = IMBIE_total_mass_change_sum\n",
    "    results['delta_masschange'] = delta_masschange\n",
    "    \n",
    "    # Check if all required (regional) files are available for Antarctica\n",
    "    if icesheet == \"Antarctica\":\n",
    "        region_mass_change_sums = basin_result.get('region_mass_change_sums') \n",
    "        print_regionalresult_check = 'NO'\n",
    "        if (obs_east_filename and os.path.exists(obs_east_filename)) and \\\n",
    "           (obs_west_filename and os.path.exists(obs_west_filename)) and \\\n",
    "           (obs_peninsula_filename and os.path.exists(obs_peninsula_filename)):\n",
    "            \n",
    "            print_regionalresult_check = 'YES' \n",
    "            \n",
    "            # Calculate total mass for each region\n",
    "            IMBIE_total_mass_change_sum_east = sum_MassBalance(obs_east_filename, start_date, end_date)\n",
    "            IMBIE_total_mass_change_sum_west = sum_MassBalance(obs_west_filename, start_date, end_date)\n",
    "            IMBIE_total_mass_change_sum_peninsula = sum_MassBalance(obs_peninsula_filename, start_date, end_date)\n",
    "            \n",
    "            # Calculate the difference of IMBIE-model mass change for each region\n",
    "            delta_masschange_east = IMBIE_total_mass_change_sum_east - region_mass_change_sums['East']\n",
    "            delta_masschange_west = IMBIE_total_mass_change_sum_west - region_mass_change_sums['West']\n",
    "            delta_masschange_peninsula = IMBIE_total_mass_change_sum_peninsula - region_mass_change_sums['Peninsula']\n",
    "            \n",
    "            # Store regional results in the dictionary\n",
    "            results['IMBIE_total_mass_change_sum_east'] = IMBIE_total_mass_change_sum_east\n",
    "            results['IMBIE_total_mass_change_sum_west'] = IMBIE_total_mass_change_sum_west\n",
    "            results['IMBIE_total_mass_change_sum_peninsula'] = IMBIE_total_mass_change_sum_peninsula\n",
    "            \n",
    "            results['delta_masschange_east'] = delta_masschange_east\n",
    "            results['delta_masschange_west'] = delta_masschange_west\n",
    "            results['delta_masschange_peninsula'] = delta_masschange_peninsula\n",
    "\n",
    "        # Store regional check result in the dictionary\n",
    "        results['print_regionalresult_check'] = print_regionalresult_check\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mass_change_comparison(icesheet,basin_result,results):\n",
    "\n",
    "    print_regionalresult_check=results.get('print_regionalresult_check')\n",
    "\n",
    "    basin_mass_change_sums = basin_result['basin_mass_change_sums']\n",
    "    # Apply formatting to two decimal places for the model mass change\n",
    "    formatted_mass_change_sums = basin_mass_change_sums.apply(lambda x: f\"{x:.2f}\")\n",
    "    \n",
    "    #Placeholders for 'IMBIE mass change' and 'Residual' columns\n",
    "    imbie_mass_change = '--'\n",
    "    residual_mass_change = '--'\n",
    "    \n",
    "    print(\"\\nMass change comparison (total): 2006-01-01 - 2015-01-01\")\n",
    "    # Define column headers with fixed width for alignment\n",
    "    print(f\"{'Basin':<10} {'Model mass change (Gt)':<25} {'IMBIE mass change (Gt)':<25} {'Residual (Gt)':<25}\")\n",
    "    \n",
    "    # Loop through and print each basin's subregion mass change output with fixed-width formatting\n",
    "    for subregion, model_mass_change in formatted_mass_change_sums.items():\n",
    "        print(f\"{subregion:<10} {model_mass_change:<25} {imbie_mass_change:<25} {residual_mass_change:<25}\")\n",
    "    \n",
    "    if icesheet == \"Antarctica\":\n",
    "\n",
    "        if print_regionalresult_check == 'YES':          \n",
    "            # Use .get() for safety if it's None\n",
    "            region_mass_change_sums = basin_result.get('region_mass_change_sums') \n",
    "            # Remove 'Regions' and index name\n",
    "            region_mass_change_sums.name = None\n",
    "            region_mass_change_sums.index.name = None\n",
    "            \n",
    "            # Format the Series without displaying the 'dtype'\n",
    "            formatted_region_mass_change = region_mass_change_sums.apply(lambda x: f\"{x:.2f}\")\n",
    "            \n",
    "            # Define regions, totals, and delta changes\n",
    "            regions = [\"East\", \"West\", \"Peninsula\", \"Islands\"]\n",
    "            IMBIE_totals = [results.get('IMBIE_total_mass_change_sum_east'), results.get('IMBIE_total_mass_change_sum_west'), \n",
    "                            results.get('IMBIE_total_mass_change_sum_peninsula')]\n",
    "            delta_changes = [results.get('delta_masschange_east'), results.get('delta_masschange_west'), \n",
    "                             results.get('delta_masschange_peninsula')]\n",
    "            \n",
    "            # Loop through regions and print formatted output\n",
    "            for region, total, delta in zip(regions, IMBIE_totals, delta_changes):\n",
    "                mass_change = formatted_region_mass_change.get(region, \"N/A\")  # Get the mass change for the region\n",
    "                print(f\"{region:<10} {mass_change:<25} {total:<25.2f} {delta:<25.2f}\")\n",
    "    \n",
    "    IMBIE_total_mass_change_sum = results.get('IMBIE_total_mass_change_sum')\n",
    "    delta_masschange = results.get('delta_masschange')\n",
    "    model_total_mass_balance = basin_result['model_total_mass_balance']\n",
    "    # Print total mass balance with formatted columns    \n",
    "    print(f\"{'Total':<10} {model_total_mass_balance.round(2):<25} {IMBIE_total_mass_change_sum:<25.2f} {delta_masschange:<25.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def write_mass_change_comparison(icesheet, basin_result, results,mass_balance_type,start_date,end_date,csv_filename):\n",
    "    print_regionalresult_check = results.get('print_regionalresult_check')\n",
    "\n",
    "    # Data for basin mass change\n",
    "    basin_mass_change_sums = basin_result['basin_mass_change_sums']\n",
    "    formatted_mass_change_sums = basin_mass_change_sums.apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "    # Initialize list to store rows of data for CSV\n",
    "    data_rows = []\n",
    "\n",
    "    # Add mass change comparison header as the first row with two columns\n",
    "    data_rows.append([f\"Mass change comparison ({mass_balance_type})\", f\"{start_date} - {end_date}\"])\n",
    "\n",
    "\n",
    "    # Add column headers for basin mass change\n",
    "    data_rows.append(['Basin', 'Model mass change (Gt)', 'IMBIE mass change (Gt)', 'Residual (Gt)'])\n",
    "\n",
    "    # Placeholders for 'IMBIE mass change' and 'Residual' columns\n",
    "    imbie_mass_change = '--'\n",
    "    residual_mass_change = '--'\n",
    "\n",
    "    # Loop through and collect each basin's subregion mass change\n",
    "    for subregion, model_mass_change in formatted_mass_change_sums.items():\n",
    "        data_rows.append([subregion, model_mass_change, imbie_mass_change, residual_mass_change])\n",
    "\n",
    "    if icesheet == \"Antarctica\" and print_regionalresult_check == 'YES':\n",
    "        region_mass_change_sums = basin_result.get('region_mass_change_sums')\n",
    "\n",
    "        if region_mass_change_sums is not None:\n",
    "            formatted_region_mass_change = region_mass_change_sums.apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "            # Define regions, totals, and delta changes\n",
    "            regions = [\"East\", \"West\", \"Peninsula\", \"Islands\"]\n",
    "            IMBIE_totals = [results.get('IMBIE_total_mass_change_sum_east'), results.get('IMBIE_total_mass_change_sum_west'),\n",
    "                            results.get('IMBIE_total_mass_change_sum_peninsula')]\n",
    "            delta_changes = [results.get('delta_masschange_east'), results.get('delta_masschange_west'),\n",
    "                             results.get('delta_masschange_peninsula')]\n",
    "\n",
    "            # Collect each region's mass change\n",
    "            for region, total, delta in zip(regions, IMBIE_totals, delta_changes):\n",
    "                mass_change = formatted_region_mass_change.get(region, \"N/A\")\n",
    "                data_rows.append([region, mass_change, f\"{total:.2f}\" if total is not None else \"N/A\", \n",
    "                                  f\"{delta:.2f}\" if delta is not None else \"N/A\"])\n",
    "\n",
    "    # Collect total mass balance\n",
    "    IMBIE_total_mass_change_sum = results.get('IMBIE_total_mass_change_sum')\n",
    "    delta_masschange = results.get('delta_masschange')\n",
    "    model_total_mass_balance = basin_result['model_total_mass_balance']\n",
    "\n",
    "\n",
    "    # Add the total mass balance row\n",
    "    data_rows.append(['Total', f\"{model_total_mass_balance:.2f}\", f\"{IMBIE_total_mass_change_sum:.2f}\", \n",
    "                      f\"{delta_masschange:.2f}\"])\n",
    "\n",
    "    # Convert the data rows into a pandas DataFrame\n",
    "    df = pd.DataFrame(data_rows)\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    print(f\"Writing data to CSV file: {csv_filename}\")\n",
    "    df.to_csv(csv_filename, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:/home/jovyan/shared-public/CmCt/models/ISMIP6/lithk_AIS_AWI_PISM1_hist_std.nc\n",
      "Time range: 2006-01-01 00:00:00 to 2015-01-01 00:00:00\n",
      "The selected dates 2006-01-01 and 2014-01-01 are within the range of the model data.\n",
      "Writing data to CSV file: /home/jovyan/CmCt/notebooks/IMBIE/lithk_AIS_AWI_PISM1_hist_std.csv\n"
     ]
    }
   ],
   "source": [
    "# Set shapefile path and projection and IMBIE csv_file\n",
    "if icesheet == \"Greenland\":  \n",
    "    # Template for the model filenames\n",
    "    mod_filename_template = '/home/jovyan/shared-public/CmCt/models/ISMIP6/lithk_GIS_*_*_historical.nc'\n",
    "    \n",
    "elif icesheet== \"Antarctica\":    \n",
    "    # Template for the model filenames\n",
    "    mod_filename_template = '/home/jovyan/shared-public/CmCt/models/ISMIP6/lithk_AIS_*_*_hist_std.nc'\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Invalid iceshee value. Must be 'Greenland' or 'Antarctica'.\") \n",
    "\n",
    "\n",
    "# Get the list of all model data files\n",
    "nc_filenames = glob.glob(mod_filename_template)\n",
    "\n",
    "# Loop through each file \n",
    "for nc_filename in nc_filenames:\n",
    "    print(f\"Processing:{nc_filename}\")\n",
    "    # Process the model data and get mass balance and basin sums\n",
    "    basin_result = process_model_data(nc_filename) \n",
    "\n",
    "    # Process the IMBIE data and get results in a dictionary\n",
    "    results = process_IMBIE(obs_filename, start_date, end_date, icesheet,  basin_result,obs_east_filename, obs_west_filename, \n",
    "                            obs_peninsula_filename)\n",
    "\n",
    "\n",
    "    # # Print the mass change comparison using the processed results\n",
    "    # print_mass_change_comparison(icesheet,basin_result,results)\n",
    "\n",
    "    # Extract the base name of the nc file (without .nc extension)\n",
    "    nc_base_filename = os.path.basename(nc_filename).replace('.nc', '')\n",
    "    \n",
    "    # Create the CSV filename by combining the output path and the base nc filename with .csv extension\n",
    "    csv_filename = os.path.join(output_path, f\"{nc_base_filename}.csv\")\n",
    "\n",
    " \n",
    "    \n",
    "    # Write  the mass change comparison  to csv file\n",
    "    write_mass_change_comparison(icesheet, basin_result, results,mass_balance_type,start_date,end_date,csv_filename)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
